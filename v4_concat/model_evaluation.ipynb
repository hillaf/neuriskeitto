{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from model import EncoderRNN, AttnDecoderRNN\n",
    "import json\n",
    "import helpers\n",
    "\n",
    "\n",
    "encoder_dict = torch.load('./model-concat.pt', map_location=torch.device('cpu'))['encoder_state_dict']\n",
    "decoder_dict = torch.load('./model-concat.pt', map_location=torch.device('cpu'))['decoder_state_dict']\n",
    "    \n",
    "with open('../project_data/project_train_data_instr.json') as json_file:\n",
    "    train_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "LEARNING_RATE = 0.01\n",
    "REPORT_EVERY = 1000\n",
    "HIDDEN_DIM = 256\n",
    "#BATCH_SIZE = 20\n",
    "#N_LAYERS = 1\n",
    "teacher_forcing_ratio = 1\n",
    "TRAIN_SET_SIZE = 1000\n",
    "n_words = 43863\n",
    "MAX_LENGTH = 159\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(10)\n",
    "\n",
    "encoder = EncoderRNN(n_words, HIDDEN_DIM).to(device)\n",
    "decoder = AttnDecoderRNN(HIDDEN_DIM, n_words, max_length=MAX_LENGTH).to(device)\n",
    "\n",
    "encoder.load_state_dict(encoder_dict)\n",
    "decoder.load_state_dict(decoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of short ingredient lists:  130567\n",
      "Average ingredient list length: 14.175872007959267\n",
      "No ingredients filtered\n",
      "Max instruction step length:  70\n",
      "Number of long instructions:  61032\n",
      "Average instruction length: 149.95270527301457\n",
      "Total instruction steps:  489828\n",
      "Recipes filtered:  61455\n",
      "Recipes left after filtering:  75241\n",
      "Recipe step pairs:  223824\n",
      "New max length:  159\n",
      "tensor([[43860],\n",
      "        [   34],\n",
      "        [   35],\n",
      "        [   36],\n",
      "        [    1],\n",
      "        [   37],\n",
      "        [   38],\n",
      "        [   39],\n",
      "        [   40],\n",
      "        [   41],\n",
      "        [   42],\n",
      "        [   43],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [    2],\n",
      "        [   45],\n",
      "        [   46],\n",
      "        [   47],\n",
      "        [   48],\n",
      "        [   49],\n",
      "        [   50],\n",
      "        [   51],\n",
      "        [   52],\n",
      "        [   27],\n",
      "        [   53],\n",
      "        [   27],\n",
      "        [43862]])\n",
      "<SOS> unsalted butter onion flour sugar powder soda cheese frozen corn kernels roasted marinated red bell peppers basil Preheat oven to 400 degrees F ( 205 degrees C ) . Butter a 9x9x2 inch baking pan . <EOS>\n",
      "<SOS> Melt 1 tablespoon butter in medium nonstick skillet over medium-low heat . Add onion and saute until tender , about 10 minutes . Cool . <EOS>\n",
      "(tensor([[43860],\n",
      "        [    0],\n",
      "        [    1],\n",
      "        [    2],\n",
      "        [    3],\n",
      "        [    4],\n",
      "        [    5],\n",
      "        [    6],\n",
      "        [    7],\n",
      "        [    8],\n",
      "        [    9],\n",
      "        [   10],\n",
      "        [   11],\n",
      "        [   12],\n",
      "        [   13],\n",
      "        [   14],\n",
      "        [   15],\n",
      "        [   16],\n",
      "        [   54],\n",
      "        [   55],\n",
      "        [   56],\n",
      "        [   57],\n",
      "        [    3],\n",
      "        [   49],\n",
      "        [   32],\n",
      "        [    5],\n",
      "        [   49],\n",
      "        [    4],\n",
      "        [   49],\n",
      "        [   58],\n",
      "        [   49],\n",
      "        [   45],\n",
      "        [   32],\n",
      "        [    6],\n",
      "        [   37],\n",
      "        [   59],\n",
      "        [   60],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [   61],\n",
      "        [   62],\n",
      "        [    1],\n",
      "        [   45],\n",
      "        [   63],\n",
      "        [   56],\n",
      "        [   64],\n",
      "        [   47],\n",
      "        [   65],\n",
      "        [   66],\n",
      "        [   67],\n",
      "        [   68],\n",
      "        [   27],\n",
      "        [43862]]), tensor([[43860],\n",
      "        [   69],\n",
      "        [   70],\n",
      "        [   45],\n",
      "        [   71],\n",
      "        [   37],\n",
      "        [   38],\n",
      "        [   60],\n",
      "        [   19],\n",
      "        [   72],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [   70],\n",
      "        [   65],\n",
      "        [   19],\n",
      "        [   73],\n",
      "        [   74],\n",
      "        [   45],\n",
      "        [   75],\n",
      "        [   47],\n",
      "        [   76],\n",
      "        [   27],\n",
      "        [   54],\n",
      "        [   37],\n",
      "        [    7],\n",
      "        [   49],\n",
      "        [    9],\n",
      "        [   49],\n",
      "        [   13],\n",
      "        [   15],\n",
      "        [   49],\n",
      "        [   16],\n",
      "        [   49],\n",
      "        [   45],\n",
      "        [    2],\n",
      "        [   27],\n",
      "        [   77],\n",
      "        [   19],\n",
      "        [   78],\n",
      "        [   33],\n",
      "        [   27],\n",
      "        [43862]]))\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "recipe_step_pairs, idx2word, word2idx, ml = helpers.get_tensor_data()\n",
    "n_words = len(word2idx)\n",
    "print(recipe_step_pairs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[43860],\n",
      "        [    0],\n",
      "        [    1],\n",
      "        [    2],\n",
      "        [    3],\n",
      "        [    4],\n",
      "        [    5],\n",
      "        [    6],\n",
      "        [    7],\n",
      "        [    8],\n",
      "        [    9],\n",
      "        [   10],\n",
      "        [   11],\n",
      "        [   12],\n",
      "        [   13],\n",
      "        [   14],\n",
      "        [   15],\n",
      "        [   16],\n",
      "        [   54],\n",
      "        [   55],\n",
      "        [   56],\n",
      "        [   57],\n",
      "        [    3],\n",
      "        [   49],\n",
      "        [   32],\n",
      "        [    5],\n",
      "        [   49],\n",
      "        [    4],\n",
      "        [   49],\n",
      "        [   58],\n",
      "        [   49],\n",
      "        [   45],\n",
      "        [   32],\n",
      "        [    6],\n",
      "        [   37],\n",
      "        [   59],\n",
      "        [   60],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [   61],\n",
      "        [   62],\n",
      "        [    1],\n",
      "        [   45],\n",
      "        [   63],\n",
      "        [   56],\n",
      "        [   64],\n",
      "        [   47],\n",
      "        [   65],\n",
      "        [   66],\n",
      "        [   67],\n",
      "        [   68],\n",
      "        [   27],\n",
      "        [43862]]), tensor([[43860],\n",
      "        [   69],\n",
      "        [   70],\n",
      "        [   45],\n",
      "        [   71],\n",
      "        [   37],\n",
      "        [   38],\n",
      "        [   60],\n",
      "        [   19],\n",
      "        [   72],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [   70],\n",
      "        [   65],\n",
      "        [   19],\n",
      "        [   73],\n",
      "        [   74],\n",
      "        [   45],\n",
      "        [   75],\n",
      "        [   47],\n",
      "        [   76],\n",
      "        [   27],\n",
      "        [   54],\n",
      "        [   37],\n",
      "        [    7],\n",
      "        [   49],\n",
      "        [    9],\n",
      "        [   49],\n",
      "        [   13],\n",
      "        [   15],\n",
      "        [   49],\n",
      "        [   16],\n",
      "        [   49],\n",
      "        [   45],\n",
      "        [    2],\n",
      "        [   27],\n",
      "        [   77],\n",
      "        [   19],\n",
      "        [   78],\n",
      "        [   33],\n",
      "        [   27],\n",
      "        [43862]]))\n"
     ]
    }
   ],
   "source": [
    "print(recipe_step_pairs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction step <SOS> shells sausage sauce cheese shredded mozzarella cheese cheese seasoning powder Cook manicotti according to package directions . Meanwhile , in a skillet , cook the sausage over medium heat until no longer pink ; drain . Stir in spaghetti sauce . <EOS>\n",
      "Next step <SOS> Drain manicotti and rinse with cold water . In a bowl , combine the ricotta cheese , 1/4 cup of mozzarella cheese , Parmesan cheese , Italian seasoning , garlic powder and pepper . Carefully stuff manicotti . Place in a greased 11-in . x 7-in . x 2-in . baking dish . Top with sausage mixture . <EOS>\n",
      "Generated instructions <SOS> In a medium bowl , mix together the eggs , Parmesan cheese , and Parmesan cheese . <EOS>\n",
      "Loss:  7.889027913411458\n",
      "\n",
      "Instruction step <SOS> rice olive oil bell peppers onion spinach beans mushrooms chili powder paprika beans tortillas sauce blend Heat olive oil in a large skillet over medium heat . Add bell peppers , onion , spinach , green beans , and mushrooms ; cook and stir until soft , about 8 minutes . Season with chili powder and paprika . <EOS>\n",
      "Next step <SOS> Spoon refried beans into a microwave-safe container . Cover and microwave until hot , about 3 minutes . <EOS>\n",
      "Generated instructions <SOS> Stir together the rice , the bowl until the mixture is thoroughly heated . <EOS>\n",
      "Loss:  6.889458465576172\n",
      "\n",
      "Instruction step <SOS> butter sugar Almonds BAKER 'S Semi-Sweet Baking Chocolate pistachios Bake 12 to 15 min . or until lightly browned . Cool on wire racks . <EOS>\n",
      "Next step <SOS> Melt chocolate as directed on pkg . Dip one end of each cooled cookie into melted chocolate ; sprinkle with pistachios . Return to wire racks ; let stand until set . <EOS>\n",
      "Generated instructions <SOS> Beat eggs , sugar , vanilla extract , medium bowl until well blended . Stir in chocolate chips . Pour into prepared pan . <EOS>\n",
      "Loss:  9.790749942555147\n",
      "\n",
      "Instruction step <SOS> Wafers margarine PHILADELPHIA Neufchatel Cheese sugar tub COOL WHIP FREE Whipped Topping thawed bananas milk Filling BAKER 'S Semi-Sweet Baking Chocolate Mix Neufchatel cheese and powdered sugar with wooden spoon until well blended . Gently stir in 1-1/2 cups of the whipped topping . Spoon mixture evenly onto crust ; spread carefully . Cut bananas in half crosswise ; cut each piece lengthwise in half . Arrange banana pieces over Neufchatel cheese mixture . <EOS>\n",
      "Next step <SOS> Pour milk into large bowl . Add dry pudding mixes . Beat with wire whisk 2 min . Spoon over bananas . Spread with remaining whipped topping . Sprinkle evenly with chocolate . Refrigerate at least 3 hours before serving . <EOS>\n",
      "Generated instructions <SOS> Refrigerate 4 hours or until set . <EOS>\n",
      "Loss:  9.25351307003997\n",
      "\n",
      "Instruction step <SOS> turkey celery pepper onion can condensed cream of mushroom soup sliced water chestnuts jar sliced mushrooms jar diced pimientos sauce seasoning cream wide egg noodles In a large skillet over medium heat , brown the turkey . Add celery , green pepper and onion ; cook until tender . Stir in soup , water chestnuts , mushrooms , pimientos , soy sauce , salt and lemon pepper . Reduce heat ; simmer for 20 minutes . <EOS>\n",
      "Next step <SOS> Remove from the heat ; add sour cream and noodles . Spoon half into a freezer container ; cover and freeze for up to 3 months . Place remaining mixture in a greased 2-qt . baking dish . Cover and bake at 350 degrees F for 30-35 minutes or until heated through . <EOS>\n",
      "Generated instructions <SOS> In a large bowl , combine the sour cream , sour cream , sour cream , and sour cream , Stir until well blended . <EOS>\n",
      "Loss:  9.881541859019887\n",
      "\n",
      "Instruction step <SOS> potatoes flour Turn dough out onto a lightly floured work surface . Knead dough lightly and roll dough out to about 1/2-inch thick . Cut into six triangular wedges . <EOS>\n",
      "Next step <SOS> Working in batches , cook scones , turning once on hot griddle until golden brown , 4 to 5 minutes per side . <EOS>\n",
      "Generated instructions <SOS> Roll out dough into a 12-inch circle . <EOS>\n",
      "Loss:  8.555946655273438\n",
      "\n",
      "Instruction step <SOS> beans large onion garlic cloves cilantro parsley cumin cayenne juice oil dill mint wedges Simmer beans , onion , garlic , salt , and water in a 3-quart saucepan , covered , until beans are tender , about 8 minutes . Stir in cilantro and parsley and let stand , uncovered , 5 minutes . <EOS>\n",
      "Next step <SOS> Drain bean mixture in a sieve and transfer to a food processor . Add cumin , cayenne , 3 tablespoons lemon juice , 4 tablespoons oil , dill , and mint and purée until smooth . Transfer to a bowl and cool to room temperature , stirring occasionally . Season with salt and pepper and add lemon juice to taste . <EOS>\n",
      "Generated instructions <SOS> Stir together lemon juice , garlic , and lemon juice in a bowl until combined . <EOS>\n",
      "Loss:  8.212559291294642\n",
      "\n",
      "Instruction step <SOS> butter powder bread oregano cheese sauce Place baking sheet under the broiler for 2 to 3 minutes , until golden brown . Remove pan from oven , flip sandwiches , and brush the other sides with butter , and sprinkle with oregano . Return to the broiler , and cook until golden , about 2 minutes . <EOS>\n",
      "Next step <SOS> Cut sandwiches in half diagonally , and serve immediately with vodka sauce on the side for dipping . <EOS>\n",
      "Generated instructions <SOS> Serve immediately , <EOS>\n",
      "Loss:  6.173389053344726\n",
      "\n",
      "Instruction step <SOS> olive oil asparagus trimmed Kosher salt butter shiitake mushrooms stems removed small shallot oregano thyme fettuccine Parmesan grated yolks* Meanwhile , cook pasta in a large pot of boiling salted water , stirring occasionally , until al dente . Drain , reserving 1 cup pasta cooking liquid . <EOS>\n",
      "Next step <SOS> Add pasta , 1/2 cup pasta cooking liquid , and 3 ounces Parmesan to skillet . Cook , tossing and adding more pasta cooking liquid as needed , until sauce coats pasta , about 2 minutes ; season with salt and pepper . <EOS>\n",
      "Generated instructions <SOS> In a large bowl , toss together asparagus and asparagus and and remaining vinaigrette . <EOS>\n",
      "Loss:  8.305322265625\n",
      "\n",
      "Instruction step <SOS> grapefruits boneless skinless chicken breasts mustard powder cinnamon coriander ginger pepper butter sauce hot sauce lettuce radishes With a sharp knife , remove the peel and white pith from grapefruits and discard . Cut the grapefruit segments from the surrounding membranes , letting them drop into a small bowl . Working over a large bowl , squeeze the remaining membranes to extract the juice . Set the segments and juice aside separately . <EOS>\n",
      "Next step <SOS> Position rack in upper third of oven ; preheat broiler . Line a broiler pan or baking sheet with foil . <EOS>\n",
      "Generated instructions <SOS> In a medium bowl , mix together the mustard , mustard , mustard , and black pepper . <EOS>\n",
      "Loss:  12.372938073199728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from helpers import idx_to_words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "def evaluate(encoder, decoder, input_tensor, gold_standard):\n",
    "    with torch.no_grad():\n",
    "        max_length = MAX_LENGTH\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden(device)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        loss = 0\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[word2idx['<SOS>']]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if di < len(gold_standard):\n",
    "                loss += loss_function(decoder_output, gold_standard[di])\n",
    "            else:\n",
    "                loss += loss_function(decoder_output, gold_standard[-1])\n",
    "            if topi.item() == word2idx['<EOS>']:\n",
    "                if di < len(gold_standard) and gold_standard[di] !=  word2idx['<EOS>']:\n",
    "                    for dj in range(di, len(gold_standard)):\n",
    "                        loss += loss_function(decoder_output, gold_standard[dj])\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx2word[str(topi.item())])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, loss.item()/len(gold_standard), decoder_attentions\n",
    "\n",
    "    \n",
    "def random_evaluate(evaluation_data, n=10):\n",
    "    for i in range(n):\n",
    "        pair = choice(evaluation_data)\n",
    "        print('Instruction step', idx_to_words(pair[0], idx2word))\n",
    "        print('Next step', idx_to_words(pair[1], idx2word))\n",
    "        output_words, loss, attentions = evaluate(encoder, decoder, pair[0].to(device), pair[1].to(device))\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('Generated instructions', output_sentence)\n",
    "        print(\"Loss: \", loss)\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "def evaluate_with_given_input(pair):\n",
    "    #print('Instruction step', idx_to_words(pair[0], idx2word))\n",
    "    #print('Next step', idx_to_words(pair[1], idx2word))\n",
    "    output_words, loss, attentions = evaluate(encoder, decoder, pair[0].to(device), pair[1].to(device))\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    #print('Generated instructions', output_sentence)\n",
    "    return output_sentence, loss, attentions\n",
    "\n",
    "    \n",
    "def tokenize(instruction_step):\n",
    "    words_tokenized = word_tokenize(instruction_step)\n",
    "    return words_tokenized\n",
    "\n",
    "\n",
    "def add_helper_tokens(step_tokenized):\n",
    "    new_step = ['<SOS>']\n",
    "    new_step.extend(step_tokenized)\n",
    "    new_step.append('<EOS>')\n",
    "    return new_step\n",
    "\n",
    "def to_idx_repr(tokenized_instruction):\n",
    "    idx_list = [word2idx[w] if w in word2idx else word2idx['<LN>'] for w in tokenized_instruction]\n",
    "    return idx_list\n",
    "    \n",
    "\n",
    "def prepare_input_instruction(text):\n",
    "    tokenized = tokenize(text)\n",
    "    tokenized_h = add_helper_tokens(tokenized)\n",
    "    idx_list = to_idx_repr(tokenized_h)\n",
    "    return idx_list\n",
    "\n",
    "def prepare_input_instruction_eval(text):\n",
    "    tokenized = tokenize(text)\n",
    "    tokenized_h = add_helper_tokens(tokenized[3:-3])\n",
    "    tensor = to_idx_repr(tokenized_h)\n",
    "    return tensor\n",
    "\n",
    "def remove_helper_tokens(text):\n",
    "    helpers_r = r'(<SOS>)|(<EOS>)'\n",
    "    cleaned_text = re.sub(helpers_r, \"\", text, count=2)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def generate_next_steps(first_step):\n",
    "    print('Input: ', first_step)\n",
    "    steps = []\n",
    "    made_up_instruction = first_step\n",
    "    i = 1\n",
    "    while len(steps) < 10 and made_up_instruction != \"<SOS> <EOS>\":\n",
    "        tensor = prepare_input_instruction(made_up_instruction)\n",
    "        made_up_instruction = evaluate_with_given_input(tensor)\n",
    "        steps.append(made_up_instruction)\n",
    "        print(i,\".\", remove_helper_tokens(made_up_instruction))\n",
    "        i = i + 1\n",
    "\n",
    "        \n",
    "def get_instruction_steps(recipes, ingredients):\n",
    "    recipe_step_pairs = []\n",
    "    for i, recipe in enumerate(recipes):\n",
    "        ingr_str = \" \".join(ingredients[i])\n",
    "        ingr = prepare_input_instruction(ingr_str)\n",
    "        for i, instr_step in enumerate(recipe[:-1]):\n",
    "            ingr_tensor = ingr[:-1]\n",
    "            instr_tensor = instr_step[1:]\n",
    "            ingr_tensor.extend(instr_tensor)\n",
    "            ingr_tensor = torch.tensor(ingr_tensor).view(-1, 1)\n",
    "            target = torch.tensor(recipe[i+1]).view(-1, 1)\n",
    "            recipe_step_pairs.append((ingr_tensor, target))\n",
    "    print(\"Recipe step pairs: \", len(recipe_step_pairs))\n",
    "    return recipe_step_pairs\n",
    "\n",
    "\n",
    "def preprocess_ingredients(ingredient_data):\n",
    "    # Extract quantity and quantity variable information\n",
    "    amount_r = r'((\\d{1,2}|½|¼)(\\/\\d)?(\\s\\d\\/\\d)?(\\s\\(\\d{1,2}\\sounce\\))?)'\n",
    "    measure_r = r'(cup(s)?|teaspoon(s)?|packet(s)?|box(es)?|package(s)?|tablespoon(s)?|ounce(s)?|pinch|square(s)?|pound(s)?|slice(s)?|bunch|cube(s)?|can(s)?|pint(s)?|drop(s)?|quart(s)?)'\n",
    "    random_notes_r = r'(\\(.*\\))'\n",
    "\n",
    "    parsed_ingredients_per_recipe = []\n",
    "    for rec in ingredient_data:\n",
    "        parsed_ingredients = {}\n",
    "        for ing in rec:\n",
    "            amount = re.search(amount_r, ing)\n",
    "            measure = re.search(measure_r, ing)\n",
    "            content = re.sub(amount_r, \"\", ing, count=1)\n",
    "            content = re.sub(measure_r, \"\", content, count=1)\n",
    "            content = re.sub(random_notes_r, \"\", content)\n",
    "            content = content.strip()\n",
    "            if amount and measure:\n",
    "                amount_re = re.sub(random_notes_r, \"\", amount.group(0))\n",
    "                parsed_ingredients[content] = (amount_re, measure.group(0))\n",
    "            elif amount:\n",
    "                amount_re = re.sub(random_notes_r, \"\", amount.group(0))\n",
    "                parsed_ingredients[content] = (amount_re, \"\")\n",
    "            elif measure:\n",
    "                parsed_ingredients[content] = (\"\", measure.group(0))\n",
    "            else:\n",
    "                parsed_ingredients[content] = (\"\", \"\")\n",
    "        parsed_ingredients_per_recipe.append(parsed_ingredients)\n",
    "\n",
    "    print(len(parsed_ingredients_per_recipe))\n",
    "    print(parsed_ingredients_per_recipe[0])\n",
    "\n",
    "    # Get ingredient names\n",
    "    ingr_names_per_recipe = []\n",
    "    for ingr in parsed_ingredients_per_recipe:\n",
    "        ingr_names = [key.strip() for key in ingr.keys()]\n",
    "        ingr_names_per_recipe.append(ingr_names)\n",
    "\n",
    "    ingr_names_comma = r'.*,'\n",
    "    ingr_names_end = r'\\s(\\S+)$'\n",
    "\n",
    "    simple_ingr_names = []\n",
    "    for rec in ingr_names_per_recipe:\n",
    "        simple_rec = []\n",
    "        for i in rec:\n",
    "            name = re.search(ingr_names_comma, i)\n",
    "            if not name:\n",
    "                name = re.search(ingr_names_end, i)\n",
    "            if name:\n",
    "                simple_rec.append(name.group(0).replace(',','').strip())\n",
    "        simple_ingr_names.append(simple_rec)\n",
    "    print(simple_ingr_names[0])\n",
    "    \n",
    "    # Create a list and set of all the ingredients together\n",
    "    list_of_ingredients = []\n",
    "    for rec in simple_ingr_names:\n",
    "        list_of_ingredients.extend(rec)\n",
    "\n",
    "    ingr_counts = Counter(list_of_ingredients)\n",
    "    print(ingr_counts.most_common(30))\n",
    "    set_of_ingredients = set(list_of_ingredients)\n",
    "    print(\"Number of simplified ingredients: \", len(set_of_ingredients))\n",
    "    return ingr_names_per_recipe\n",
    "\n",
    "\n",
    "def preprocess_instruction_data_from_recipes(recipes, limit):\n",
    "    preprocessed = []\n",
    "    filtered_out = 0\n",
    "    rm_indices = []\n",
    "    for i, rec in enumerate(recipes):\n",
    "        ingredients, instructions = rec\n",
    "        rec_steps = []\n",
    "        use_rec = True\n",
    "        for step in instructions:\n",
    "            if len(step) < limit:\n",
    "                ingr_str = \" \".join(ingredients)\n",
    "                instr_tensor = prepare_input_instruction(step)\n",
    "                rec_steps.append(instr_tensor)\n",
    "            else:\n",
    "                use_rec = False\n",
    "                filtered_out = filtered_out + 1\n",
    "                rm_indices.append(i)\n",
    "        if use_rec:\n",
    "            preprocessed.append(rec_steps)\n",
    "    print(filtered_out, \" recipes filtered out\")\n",
    "    return preprocessed, rm_indices\n",
    "\n",
    "\n",
    "#made_up_instruction = \"chicken Italian-seasoned bread crumbs small onion cloves garlic taste oil Mix ground chicken , 1/4 cup bread crumbs , onion , egg , garlic , salt , and black pepper in a bowl . Moisten hands and shape chicken mixture , 2 tablespoons at a time , into flat , oval-shaped patties .\"\n",
    "#generate_next_steps(made_up_instruction)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "random_evaluate(recipe_step_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "cookstr = [json.loads(line) for line in open('../../original_data/cookstr-recipes.json', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7918\n",
      "{'softened butter': ('1', 'tablespoon'), 'flour': ('2', 'tablespoons'), 'sifted cake flour': ('3', 'cups'), 'double-acting baking powder': ('4', 'teaspoons'), 'salt': ('½', 'teaspoon'), 'unsalted butter, at room temperature': ('8', 'ounces'), 'granulated sugar': ('2', 'cups'), 'eggs, at room temperature': ('4', ''), 'milk, at room temperature': ('1', 'cup'), 'to 1½  vanilla extract': ('1', 'teaspoons'), '¾  strained orange juice': ('', 'cup'), 'lemon juice': ('2', 'tablespoons'), '¾  granulated sugar': ('', 'cup'), 'finely grated orange rind': ('1', 'tablespoon')}\n",
      "['butter', 'flour', 'powder', 'unsalted butter', 'sugar', 'eggs', 'milk', 'extract', 'juice', 'juice', 'sugar', 'rind']\n",
      "[('oil', 3711), ('pepper', 3065), ('salt', 2158), ('sugar', 1815), ('flour', 1559), ('juice', 1375), ('butter', 1158), ('powder', 1013), ('vinegar', 953), ('sauce', 944), ('leaves', 940), ('cream', 917), ('water', 874), ('parsley', 787), ('cheese', 746), ('taste', 706), ('onion', 687), ('milk', 654), ('extract', 651), ('seeds', 601), ('cloves garlic', 582), ('garlic cloves', 560), ('wine', 553), ('mL', 537), ('eggs', 511), ('garlic', 462), ('unsalted butter', 445), ('ginger', 440), ('lemon', 417), ('mustard', 401)]\n",
      "Number of simplified ingredients:  12550\n",
      "['softened butter', 'flour', 'sifted cake flour', 'double-acting baking powder', 'salt', 'unsalted butter, at room temperature', 'granulated sugar', 'eggs, at room temperature', 'milk, at room temperature', 'to 1½  vanilla extract', '¾  strained orange juice', 'lemon juice', '¾  granulated sugar', 'finely grated orange rind']\n",
      "26620  recipes filtered out\n",
      "[[43860, 54, 294, 57, 74, 262, 19, 72, 27, 905, 37, 57, 397, 37, 29, 1125, 1812, 458, 129, 769, 19, 143, 1685, 27, 43862]]\n",
      "Recipe step pairs:  469\n",
      "<SOS> Achiote Oil Recaito tomato paste chopped fresh oregano or 2 teaspoons dried oregano turkey ham , finally chopped In a small skillet , heat oil over medium heat ; combine ingredients ; sauté lightly for 5 minutes . <EOS>\n",
      "<SOS> If you like your food spicy , add chile to taste . <EOS>\n"
     ]
    }
   ],
   "source": [
    "test_ingr = [rec['ingredients'] for rec in cookstr]\n",
    "test_instr = [rec['instructions'] for rec in cookstr]\n",
    "\n",
    "preprocessed_ingredients = preprocess_ingredients(test_ingr)\n",
    "print(preprocessed_ingredients[0])\n",
    "\n",
    "recipes = [(preprocessed_ingredients[i], test_instr[i]) for i, rec in enumerate(preprocessed_ingredients)]\n",
    "\n",
    "limit = 120\n",
    "prcessed, rm_indices = preprocess_instruction_data_from_recipes(recipes, limit)\n",
    "print(prcessed[0])\n",
    "\n",
    "preprocessed_ingredients = [ing for i, ing in enumerate(preprocessed_ingredients) if i not in rm_indices]\n",
    "\n",
    "test_data_steps = get_instruction_steps(prcessed, preprocessed_ingredients)\n",
    "\n",
    "print(helpers.idx_to_words(test_data_steps[1][0], idx2word))\n",
    "print(helpers.idx_to_words(test_data_steps[1][1], idx2word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for test set:  12.771939133316128\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "outputs = []\n",
    "\n",
    "for t in test_data_steps:\n",
    "    output, loss, attention = evaluate_with_given_input(t)\n",
    "    total_loss += loss\n",
    "    outputs.append(output)\n",
    "    \n",
    "print(\"Average loss for test set: \", total_loss/len(test_data_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction step <SOS> lemon juice balsamic vinegar clove garlic , peeled and minced plain yogurt Dijon mustard sugar dried sage dried thyme dried basil dried oregano cinnamon olive oil extra virgin olive oil Combine all in a 2-cup glass measure . Blend till smooth with a hand-held blender <EOS>\n",
      "Next step <SOS> Thin with a little water if needed . Makes about one cup . <EOS>\n",
      "Generated instructions <SOS> Whisk vinegar , lemon juice , garlic , and lemon juice together in a bowl ; <EOS>\n",
      "Loss:  10.705683390299479\n",
      "\n",
      "Instruction step <SOS> salad greens store-bought rotisserie chicken , shredded pear ? 2 cucumber , English ? 2 bulb fennel Belgian endives jar artichoke hearts packed in oil , drained tomatoes cut into 8 each ? 4 sea salt olive oil red wine vinegar ? 2 dried cherries or cranberries ? 4 goat cheese , crumbled Large salad bowl Food processor Large spoons for tossing salad Wash and dry the salad greens . Put the greens in a large salad bowl . Add the chicken . <EOS>\n",
      "Next step <SOS> In a food processor , thinly slice the pear , cucumber , fennel , and Belgian endives . Toss with the greens . <EOS>\n",
      "Generated instructions <SOS> In a medium bowl , toss together the romaine and romaine and romaine and and pine nuts . <EOS>\n",
      "Loss:  5.386737670898437\n",
      "\n",
      "Instruction step <SOS> plantains , very ripe margarine Preheat the oven to 350°F . <EOS>\n",
      "Next step <SOS> Slit skin of plantain lengthwise ; place on cookie sheet . <EOS>\n",
      "Generated instructions <SOS> In a medium bowl , mix together the eggs , the melted butter . <EOS>\n",
      "Loss:  12.222791231595552\n",
      "\n",
      "Instruction step <SOS> Ancient Harvest Quinoa Gluten Free Elbows pasta cashews water extra virgin coconut oil nutritional yeast tahini Juice of lemons Cook the pasta according to the package directions . <EOS>\n",
      "Next step <SOS> Combine the remaining ingredients in the blender and blend until smooth . <EOS>\n",
      "Generated instructions <SOS> Add the pasta machine to the bowl and toss well . <EOS>\n",
      "Loss:  4.789942060198102\n",
      "\n",
      "Instruction step <SOS> sweet potatoes packed brown sugar bourbon butter , melted Grated zest of lemon When cool enough to handle , peel the potatoes and cut into ½-inch thick slices . Place in the prepared baking dish . <EOS>\n",
      "Next step <SOS> In a small saucepan , dissolve the brown sugar in the bourbon over moderate heat . <EOS>\n",
      "Generated instructions <SOS> Bake in preheated oven until potatoes are tender , about 45 minutes . <EOS>\n",
      "Loss:  10.445607503255209\n",
      "\n",
      "Instruction step <SOS> very firm tofu or nigari tofu scallion , finely minced grated carrot finely minced celery finely minced red bell pepper toasted sunflower seeds mayonnaise salt Freshly ground black pepper Cut the tofu into tiny dice and transfer to a medium-size bowl . <EOS>\n",
      "Next step <SOS> Add the remaining ingredients and mix gently . <EOS>\n",
      "Generated instructions <SOS> In a medium bowl , mix together the mayonnaise , mayonnaise , and celery . <EOS>\n",
      "Loss:  9.889038848876954\n",
      "\n",
      "Instruction step <SOS> pickling cucumbers , peeled medium-sized onion , peeled plus 1 teaspoon kosher salt ½ lemon juice About to ½ cayenne pepper crushed , roasted sesame seeds ½ sesame oil Sprinkle with salt , mix well , and set aside in a bowl for an hour . <EOS>\n",
      "Next step <SOS> Drain all the accumulated liquid and discard . <EOS>\n",
      "Generated instructions <SOS> In a large bowl , toss together the olive oil and lemon juice and and lemon juice . <EOS>\n",
      "Loss:  18.15238037109375\n",
      "\n",
      "Instruction step <SOS> olive oil fresh orange juice fresh lemon juice tomato sauce Recaito ¼ fresh tuna papaya , cut into chunks dark-brown sugar scallions , chopped garlic clove , minced red cayenne pepper half salt , half <LN> mixture Refrigerate for 2 hours , turning fish at least once . <EOS>\n",
      "Next step <SOS> While fish is marinating , combine papaya , sugar , and lemon and orange juices in blender . <EOS>\n",
      "Generated instructions <SOS> Serve immediately . <EOS>\n",
      "Loss:  7.77476806640625\n",
      "\n",
      "Instruction step <SOS> medium leeks medium potatoes butter curry powder chicken stock or low-sodium chicken broth Salt and freshly milled pepper buttermilk chopped fresh chives Wash in cold running water to remove all sand . Drain and finely chop . <EOS>\n",
      "Next step <SOS> Peel and slice the potatoes . <EOS>\n",
      "Generated instructions <SOS> In a large bowl , whisk together 1 cup butter , and pinch of salt . <EOS>\n",
      "Loss:  19.669790267944336\n",
      "\n",
      "Instruction step <SOS> Ancient Harvest Quinoa Gluten Free Elbows pasta cashews water extra virgin coconut oil nutritional yeast tahini Juice of lemons Combine the remaining ingredients in the blender and blend until smooth . <EOS>\n",
      "Next step <SOS> Transfer the mixture from the blender to a saucepan and warm over medium heat , stirring often . <EOS>\n",
      "Generated instructions <SOS> Add the coconut milk , stir until well combined . <EOS>\n",
      "Loss:  8.158389282226562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_evaluate(test_data_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<SOS> Pour the milk into the blender or food processor until smooth . <EOS>',\n",
       " 9.907600911458333,\n",
       " tensor([[5.0157e-09, 1.5620e-08, 1.7823e-09,  ..., 5.6095e-09, 6.5664e-09,\n",
       "          7.0852e-09],\n",
       "         [6.8350e-05, 2.0942e-09, 2.2758e-06,  ..., 3.9014e-07, 3.3651e-07,\n",
       "          3.4253e-07],\n",
       "         [1.0000e+00, 3.8513e-20, 2.0532e-16,  ..., 1.2945e-18, 1.6483e-18,\n",
       "          2.5582e-18],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_given_input(test_data_steps[205])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision:  0.35466079099718434\n",
      "Average recall:  0.3903075913261745\n",
      "Average BLEU:  4.9959912399462084e-234\n",
      "Average METEOR:  0.0018386536329180355\n",
      "Average step length:  18.997867803837952\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import bleu_score, meteor_score\n",
    "from nltk.metrics import scores\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "\n",
    "avg_prec = 0\n",
    "avg_recall = 0\n",
    "avg_fscore = 0\n",
    "avg_bleu = 0\n",
    "#avg_rouge = []\n",
    "avg_meteor = 0\n",
    "avg_len = 0\n",
    "\n",
    "N = len(test_data_steps)\n",
    "results = []\n",
    "targets = []\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n",
    "\n",
    "\n",
    "for i, t in enumerate(test_data_steps):\n",
    "    input_step = [str(s) for s in t[0].flatten().tolist()]\n",
    "    target = [str(s) for s in t[1].flatten().tolist()]\n",
    "    targets.append(target)\n",
    "    result = outputs[i]\n",
    "    #print(input_step)\n",
    "    #print(target)\n",
    "    #print(result)\n",
    "    result_vec = [str(r) for r in prepare_input_instruction_eval(result)]\n",
    "    results.append(result_vec)\n",
    "    avg_len += len(result_vec)\n",
    "    # sanity check\n",
    "    #prep = idx_to_words(result_vec, idx2word)\n",
    "    #print(result_vec)\n",
    "    precision = scores.precision(set(result_vec), set(target))\n",
    "    avg_prec += precision\n",
    "    recall = scores.recall(set(result_vec), set(target))\n",
    "    avg_recall += recall\n",
    "    f_score = scores.f_measure(set(result_vec), set(target))\n",
    "    avg_fscore += f_score\n",
    "    bleu = bleu_score.sentence_bleu([target], result)\n",
    "    avg_bleu += bleu\n",
    "    rouge = scorer.score(\" \".join(target), \" \".join(result))\n",
    "    #print(rouge)\n",
    "    #avg_rouge.append(rouge['rougeL']['precision']\n",
    "    meteor = meteor_score.single_meteor_score(\" \".join(target), \" \".join(result))\n",
    "    avg_meteor += meteor\n",
    "\n",
    "print(\"Average precision: \", avg_prec/N)\n",
    "print(\"Average recall: \", avg_recall/N)\n",
    "#print(\"F1-measure: \", avg_fscore/N)\n",
    "\n",
    "print(\"Average BLEU: \", avg_bleu/N)\n",
    "print(\"Average METEOR: \", avg_meteor/N)\n",
    "#print(\"Average ROUGE-L: \", avg_bleu/N)\n",
    "print(\"Average step length: \", avg_len/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
