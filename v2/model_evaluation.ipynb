{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from model import EncoderRNN, AttnDecoderRNN\n",
    "import json\n",
    "import preprocess_for_s2s\n",
    "\n",
    "\n",
    "encoder_dict = torch.load('./model.pt', map_location=torch.device('cpu'))['encoder_state_dict']\n",
    "decoder_dict = torch.load('./model.pt', map_location=torch.device('cpu'))['decoder_state_dict']\n",
    "    \n",
    "with open('../project_data/project_train_data_instr.json') as json_file:\n",
    "    train_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCHS = 15\n",
    "LEARNING_RATE = 0.01\n",
    "REPORT_EVERY = 1000\n",
    "HIDDEN_DIM = 256\n",
    "#BATCH_SIZE = 20\n",
    "#N_LAYERS = 1\n",
    "teacher_forcing_ratio = 1\n",
    "TRAIN_SET_SIZE = 1000\n",
    "n_words = len(word2idx)\n",
    "MAX_LENGTH = 493\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_num_threads(10)\n",
    "\n",
    "encoder = EncoderRNN(n_words, HIDDEN_DIM).to(device)\n",
    "decoder = AttnDecoderRNN(HIDDEN_DIM, n_words, max_length=MAX_LENGTH).to(device)\n",
    "\n",
    "encoder.load_state_dict(encoder_dict)\n",
    "decoder.load_state_dict(decoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43860, 0, 1, 43861, 2, 43861, 3, 43861, 4, 43861, 5, 43861, 6, 43861, 7, 43861, 8, 9, 10, 43861, 11, 12, 13, 14, 15, 43861, 16, 43861, 43862]\n",
      "Max instruction step length:  70\n",
      "<SOS> Combine 1 cup flour , sugar , salt , and yeast . Mix well . Heat water and vegetable oil until warm , and add to yeast mixture along with the egg . Blend with an electric mixer at low speed until moistened . Beat for 2 additional minutes . Stir in 1 3/4 cup flour while beating , until dough pulls away from side of bowl . <EOS>\n",
      "Number of short ingredient lists:  108627\n",
      "Average ingredient list length: 22.355650494528003\n",
      "Number of long instructions:  61032\n",
      "Average instruction length: 149.95270527301457\n",
      "Training set total size:  489828\n",
      "223824\n",
      "(tensor([[43860],\n",
      "        [   17],\n",
      "        [   18],\n",
      "        [   19],\n",
      "        [   20],\n",
      "        [   21],\n",
      "        [   22],\n",
      "        [   23],\n",
      "        [   24],\n",
      "        [   21],\n",
      "        [   25],\n",
      "        [   26],\n",
      "        [   27],\n",
      "        [   28],\n",
      "        [   29],\n",
      "        [   30],\n",
      "        [   31],\n",
      "        [   32],\n",
      "        [   33],\n",
      "        [   27],\n",
      "        [43862]]), tensor([[43860],\n",
      "        [   34],\n",
      "        [   35],\n",
      "        [   36],\n",
      "        [    1],\n",
      "        [   37],\n",
      "        [   38],\n",
      "        [   39],\n",
      "        [   40],\n",
      "        [   41],\n",
      "        [   42],\n",
      "        [   43],\n",
      "        [   27],\n",
      "        [   44],\n",
      "        [    2],\n",
      "        [   45],\n",
      "        [   46],\n",
      "        [   47],\n",
      "        [   48],\n",
      "        [   49],\n",
      "        [   50],\n",
      "        [   51],\n",
      "        [   52],\n",
      "        [   27],\n",
      "        [   53],\n",
      "        [   27],\n",
      "        [43862]]))\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "recipe_step_pairs, idx2word, word2idx, ml = preprocess_for_s2s.get_tensor_data()\n",
    "n_words = len(word2idx)\n",
    "print(recipe_step_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Take some rum and sugar. Combine in a glass.\n",
      "1 .  Pour the syrup and lime juice and and lime juice . \n",
      "2 .  Place the fish and fish in the prepared baking pan and \n",
      "3 .  Bake in the preheated oven until fish is easily flaked with about 1 hour , \n",
      "4 .  Meanwhile , cook onion , onion , garlic , and salt in the same pan until fragrant , about 1 minute . \n",
      "5 .  Stir in the rice and and cook until the onion is translucent , \n",
      "6 .  Pour the liquid over the rice . stir the Pour the liquid over the rice . \n",
      "7 .  Cover the and refrigerate until chilled , about 1 hour . \n",
      "8 .  Serve the \n",
      "9 .  Garnish with \n",
      "10 .  Place 2 tablespoons of the butter over the top of the bread and \n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from preprocess_for_s2s import idx_to_words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "def evaluate(encoder, decoder, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        max_length = MAX_LENGTH\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden(device)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[word2idx['<SOS>']]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == word2idx['<EOS>']:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(idx2word[str(topi.item())])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "    \n",
    "def random_evaluate(evaluation_data, n=10):\n",
    "    for i in range(n):\n",
    "        pair = choice(evaluation_data)\n",
    "        print('Instruction step', idx_to_words(pair[0], idx2word))\n",
    "        print('Next step', idx_to_words(pair[1], idx2word))\n",
    "        output_words = evaluate(encoder, decoder, pair[0].to(device))\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('Generated instructions', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "def evaluate_with_given_input(instruction):\n",
    "    output_words = evaluate(encoder, decoder, instruction.to(device))\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    return output_sentence\n",
    "\n",
    "    \n",
    "def tokenize(instruction_step):\n",
    "    words_tokenized = word_tokenize(instruction_step)\n",
    "    return words_tokenized\n",
    "\n",
    "\n",
    "def add_helper_tokens(step_tokenized):\n",
    "    new_step = ['<SOS>']\n",
    "    new_step.extend(step_tokenized)\n",
    "    new_step.append('<EOS>')\n",
    "    return new_step\n",
    "\n",
    "def to_idx_repr(tokenized_instruction):\n",
    "    idx_list = [word2idx[w] if w in word2idx else word2idx['<LN>'] for w in tokenized_instruction]\n",
    "    instr_tensors = torch.tensor(idx_list).view(-1, 1)\n",
    "    return instr_tensors\n",
    "    \n",
    "\n",
    "def prepare_input_instruction(text):\n",
    "    tokenized = tokenize(text)\n",
    "    tokenized_h = add_helper_tokens(tokenized)\n",
    "    tensor = to_idx_repr(tokenized_h)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def remove_helper_tokens(text):\n",
    "    helpers_r = r'(<SOS>)|(<EOS>)'\n",
    "    cleaned_text = re.sub(helpers_r, \"\", text, count=2)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def preprocess_instruction_data_from_recipes(recipes, limit):\n",
    "    preprocessed = []\n",
    "    filtered_out = 0\n",
    "    for rec in recipes:\n",
    "        rec_steps = []\n",
    "        for step in rec:\n",
    "            if len(step) < limit:\n",
    "                use_rec = True\n",
    "            else:\n",
    "                filtered_out = filtered_out + 1\n",
    "                use_rec = False\n",
    "            if use_rec:\n",
    "                tensor_step = prepare_input_instruction(step)\n",
    "                rec_steps.append(tensor_step)\n",
    "        preprocessed.append(rec_steps)\n",
    "    print(filtered_out, \" recipes filtered out\")\n",
    "    return preprocessed\n",
    "            \n",
    "\n",
    "\n",
    "def generate_next_steps(first_step):\n",
    "    print('Input: ', first_step)\n",
    "    steps = []\n",
    "    made_up_instruction = first_step\n",
    "    i = 1\n",
    "    while len(steps) < 10 and made_up_instruction != \"<SOS> <EOS>\":\n",
    "        tensor = prepare_input_instruction(made_up_instruction)\n",
    "        made_up_instruction = evaluate_with_given_input(tensor)\n",
    "        steps.append(made_up_instruction)\n",
    "        print(i,\".\", remove_helper_tokens(made_up_instruction))\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "made_up_instruction = \"Take some rum and sugar. Combine in a glass.\"\n",
    "generate_next_steps(made_up_instruction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookstr = [json.loads(line) for line in open('../../original_data/cookstr-recipes.json', 'r')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32299  recipes filtered out\n"
     ]
    }
   ],
   "source": [
    "test_recs = [rec['instructions'] for rec in cookstr]\n",
    "limit = 70\n",
    "prcessed = preprocess_instruction_data_from_recipes(test_recs, limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7918"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prcessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
